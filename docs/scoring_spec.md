# 診断スコアリング仕様書 (v2024-11-02)

## 1. 入力データ構成
- Likert項目（`data/questions_likert.json`）  
  - 7件法（1〜7）を0〜6に平行移動して使用。  
  - `polarity: "positive"` の場合は `score = (value - 1) * 0.5`。  
  - `polarity: "reverse"` の場合は `score = (7 - value) * 0.5`。  
  - 主カテゴリへ最大2点、副カテゴリへ0.5点の配点を行う（重みは `relatedCategories` に記載）。
- Forced-choice項目（`data/questions_forced_choice.json`）  
  - 選択肢ごとに主カテゴリスコア（`score`×`weight`）、副カテゴリスコア（`score`×`weight`）を加算。  
  - `weight` は配点比率を表し、省略時は1.0として扱う。ScoreOptimizer により推奨値を自動算出し、必要に応じて反映できる。  
  - 信頼度入力（高=1.0, 中=0.7, 低=0.5）で全体スコアを乗算補正。  
  - 回答がoptional項目の場合は記録のみで必須スコアには含めない。
- シナリオ項目（`data/questions_scenario.json`）  
  - 主カテゴリ／副カテゴリともに `score`×`weight` を加算。  
  - 複数カテゴリに跨る場合は `weight` を用いて配点比率を調整（例: 0.67 / 0.33 など）。

## 2. 正規化フロー
1. 軸ごとに獲得点を合算。  
2. 想定最大点（`最大点 = Σ(配点)`）で割り 0〜1 のスコアへ変換。  
3. `正規化スコア = ((獲得点 / 最大点) * 100)` により 0〜100 へ変換。  
4. 全受検者の分布に対して zスコアを算出し、  
   `ハイブリッドスコア = 0.5 * 正規化スコア + 0.5 * (zスコアを0〜100へ再マップ)`。  
5. 軸間バランスを比較するためコサイン類似度で分野別レコメンドを生成。

## 3. 信頼性チェック
- 逆転項目の対（Likert）差分 > 3.0 で `consistency_flag = low`。  
- Forced-choice で連続して同じ選択肢＋低信頼度のみの場合は `confidence_flag = low`。  
- 回答時間ログで項目あたり2秒未満が20%以上の場合 `speeding_flag = true`。  
- 信頼フラグが立った軸は結果画面に注意喚起を表示。
- ScoreOptimizer は回答時間・自信度から `effectiveWeight` を算出し、短時間回答や低自信回答の影響を補正する。

## 4. 出力指標
- 大分類スコア：興味/活動/価値観/キャリア/学びスタイル/リスクの各カテゴリ（`docs/category_map.csv`参照）。  
- 中分類スコア：興味×活動など関連度の高い組合せを重み付き平均で算出。  
- 小分類レコメンド：各カテゴリスコア上位を抽出し、回答した項目IDを根拠として提示。  
- ヒートマップ／レーダーチャート／類似プロファイル比較を結果画面で利用。
- 回答品質レポート：ストレートライナー・高速回答・低自信回答を自動フラグ化し、統計出力と合わせて保守的な判断ができるようにする。

## 5. データパイプライン
1. フロントエンドで回答ログをJSON化（項目ID、選択、信頼度、回答時間）。  
2. バックエンドでスコア計算 → 標準化 → コメント生成の順に処理。  
3. `consistency_flag` 等のメタ情報を付与し結果を返却。  
4. 同意がある場合は匿名化IDで回答履歴を蓄積し、年度ごとのベンチマークを更新。  
5. パイロットデータで Cronbach’s α（0.7以上目標）、IRT（2PL→3PL）を推定し項目品質を定期評価。

## 6. 今後の改善ポイント
- 強制選択結果のばらつきを監視し、識別力の低いペアを差し替え。  
- シナリオ項目の文脈に応じてセカンダリ配点を動的調整（例：複数カテゴリへ0.67配分）。  
- コサイン類似度ベースのレコメンドに加え、クラスタリング結果の典型パターンも提示予定。
